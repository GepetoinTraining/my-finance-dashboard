# -*- coding: utf-8 -*-
# code generated by Prisma. DO NOT EDIT.
# pyright: reportUnusedImport=false
# fmt: off
from __future__ import annotations

# global imports for type checking
from builtins import bool as _bool
from builtins import int as _int
from builtins import float as _float
from builtins import str as _str
import sys
import decimal
import datetime
from typing import (
    TYPE_CHECKING,
    Optional,
    Iterable,
    Iterator,
    Sequence,
    Callable,
    ClassVar,
    NoReturn,
    TypeVar,
    Generic,
    Mapping,
    Tuple,
    Union,
    List,
    Dict,
    Type,
    Any,
    Set,
    overload,
    cast,
)
from typing_extensions import TypedDict, Literal


from typing_extensions import LiteralString
# -- template client.py.jinja --
import warnings
import logging
from datetime import timedelta
from pathlib import Path
from types import TracebackType
from typing_extensions import override

from pydantic import BaseModel

from . import types, models, errors, actions
from ._base_client import BasePrisma, UseClientDefault, USE_CLIENT_DEFAULT
from .types import DatasourceOverride, HttpConfig, MetricsFormat
from ._types import BaseModelT, PrismaMethod, TransactionId, Datasource
from .bases import _PrismaModel
from ._builder import QueryBuilder, dumps
from .generator.models import EngineType, OptionalValueFromEnvVar, BinaryPaths
from ._compat import removeprefix, model_parse
from ._constants import CREATE_MANY_SKIP_DUPLICATES_UNSUPPORTED, DEFAULT_CONNECT_TIMEOUT, DEFAULT_TX_MAX_WAIT, DEFAULT_TX_TIMEOUT
from ._raw_query import deserialize_raw_results
from ._metrics import Metrics
from .metadata import PRISMA_MODELS, RELATIONAL_FIELD_MAPPINGS
from ._transactions import AsyncTransactionManager, SyncTransactionManager

# re-exports
from ._base_client import SyncBasePrisma, AsyncBasePrisma, load_env as load_env
from ._registry import (
    register as register,
    get_client as get_client,
    RegisteredClient as RegisteredClient,
)


__all__ = (
    'ENGINE_TYPE',
    'SCHEMA_PATH',
    'BINARY_PATHS',
    'Batch',
    'Prisma',
    'Client',
    'load_env',
    'register',
    'get_client',
)

log: logging.Logger = logging.getLogger(__name__)

SCHEMA_PATH = Path('C:/Users/CLIENTE/Desktop/Extratos/my-finance-dashboard/prisma/schema.prisma')
PACKAGED_SCHEMA_PATH = Path(__file__).parent.joinpath('schema.prisma')
ENGINE_TYPE: EngineType = EngineType.binary
BINARY_PATHS = model_parse(BinaryPaths, {'queryEngine': {'windows': 'C:\\Users\\CLIENTE\\AppData\\Local\\npm-cache\\_npx\\55ad0b431757dc30\\node_modules\\prisma\\query-engine-windows.exe'}, 'introspectionEngine': {}, 'migrationEngine': {}, 'libqueryEngine': {}, 'prismaFmt': {}})


class Prisma(AsyncBasePrisma):
    # Note: these property names can be customised using `/// @Python(instance_name: '...')`
    # https://prisma-client-py.readthedocs.io/en/stable/reference/schema-extensions/#instance_name
    ingestionlogs: 'actions.IngestionLogsActions[models.IngestionLogs]'
    banktransactions: 'actions.BankTransactionsActions[models.BankTransactions]'
    internalpayments: 'actions.InternalPaymentsActions[models.InternalPayments]'
    internalreceivables: 'actions.InternalReceivablesActions[models.InternalReceivables]'

    __slots__ = (
        'ingestionlogs',
        'banktransactions',
        'internalpayments',
        'internalreceivables',
    )

    def __init__(
        self,
        *,
        use_dotenv: bool = True,
        log_queries: bool = False,
        auto_register: bool = False,
        datasource: DatasourceOverride | None = None,
        connect_timeout: int | timedelta = DEFAULT_CONNECT_TIMEOUT,
        http: HttpConfig | None = None,
    ) -> None:
        super().__init__(
            http=http,
            use_dotenv=use_dotenv,
            log_queries=log_queries,
            datasource=datasource,
            connect_timeout=connect_timeout,
        )
        self._set_generated_properties(
            schema_path=SCHEMA_PATH,
            engine_type=ENGINE_TYPE,
            prisma_models=PRISMA_MODELS,
            packaged_schema_path=PACKAGED_SCHEMA_PATH,
            relational_field_mappings=RELATIONAL_FIELD_MAPPINGS,
            preview_features=set([]),
            active_provider='postgresql',
            default_datasource_name='db',
        )

        self.ingestionlogs = actions.IngestionLogsActions[models.IngestionLogs](self, models.IngestionLogs)
        self.banktransactions = actions.BankTransactionsActions[models.BankTransactions](self, models.BankTransactions)
        self.internalpayments = actions.InternalPaymentsActions[models.InternalPayments](self, models.InternalPayments)
        self.internalreceivables = actions.InternalReceivablesActions[models.InternalReceivables](self, models.InternalReceivables)

        if auto_register:
            register(self)

    @property
    @override
    def _default_datasource(self) -> Datasource:
        return {
            'name': 'db',
            'url': OptionalValueFromEnvVar(**{'value': None, 'fromEnvVar': 'DATABASE_URL'}).resolve(),
            'source_file_path': 'C:/Users/CLIENTE/Desktop/Extratos/my-finance-dashboard/prisma/schema.prisma',
        }

    async def execute_raw(self, query: LiteralString, *args: Any) -> int:
        resp = await self._execute(
            method='execute_raw',
            arguments={
                'query': query,
                'parameters': args,
            },
            model=None,
        )
        return int(resp['data']['result'])

    @overload
    async def query_first(
        self,
        query: LiteralString,
        *args: Any,
    ) -> dict[str, Any]:
        ...

    @overload
    async def query_first(
        self,
        query: LiteralString,
        *args: Any,
        model: Type[BaseModelT],
    ) -> Optional[BaseModelT]:
        ...

    async def query_first(
        self,
        query: LiteralString,
        *args: Any,
        model: Optional[Type[BaseModelT]] = None,
    ) -> Union[Optional[BaseModelT], dict[str, Any]]:
        """This function is the exact same as `query_raw()` but returns the first result.

        If model is given, the returned record is converted to the pydantic model first,
        otherwise a raw dictionary will be returned.
        """
        results: Sequence[Union[BaseModelT, dict[str, Any]]]
        if model is not None:
            results = await self.query_raw(query, *args, model=model)
        else:
            results = await self.query_raw(query, *args)

        if not results:
            return None

        return results[0]

    @overload
    async def query_raw(
        self,
        query: LiteralString,
        *args: Any,
    ) -> List[dict[str, Any]]:
        ...

    @overload
    async def query_raw(
        self,
        query: LiteralString,
        *args: Any,
        model: Type[BaseModelT],
    ) -> List[BaseModelT]:
        ...

    async def query_raw(
        self,
        query: LiteralString,
        *args: Any,
        model: Optional[Type[BaseModelT]] = None,
    ) -> Union[List[BaseModelT], List[dict[str, Any]]]:
        """Execute a raw SQL query against the database.

        If model is given, each returned record is converted to the pydantic model first,
        otherwise results will be raw dictionaries.
        """
        resp = await self._execute(
            method='query_raw',
            arguments={
                'query': query,
                'parameters': args,
            },
            model=model,
        )
        result = resp['data']['result']
        if model is not None:
            return deserialize_raw_results(result, model=model)

        return deserialize_raw_results(result)

    def batch_(self) -> Batch:
        """Returns a context manager for grouping write queries into a single transaction."""
        return Batch(client=self)

    def tx(
        self,
        *,
        max_wait: Union[int, timedelta] = DEFAULT_TX_MAX_WAIT,
        timeout: Union[int, timedelta] = DEFAULT_TX_TIMEOUT,
    ) -> TransactionManager:
        """Returns a context manager for executing queries within a database transaction.

        Entering the context manager returns a new Prisma instance wrapping all
        actions within a transaction, queries will be isolated to the Prisma instance and
        will not be commited to the database until the context manager exits.

        By default, Prisma will wait a maximum of 2 seconds to acquire a transaction from the database. You can modify this
        default with the `max_wait` argument which accepts a value in milliseconds or `datetime.timedelta`.

        By default, Prisma will cancel and rollback ay transactions that last longer than 5 seconds. You can modify this timeout
        with the `timeout` argument which accepts a value in milliseconds or `datetime.timedelta`.

        Example usage:

        ```py
        async with client.tx() as transaction:
            user1 = await client.user.create({'name': 'Robert'})
            user2 = await client.user.create({'name': 'Tegan'})
        ```

        In the above example, if the first database call succeeds but the second does not then neither of the records will be created.
        """
        return TransactionManager(
            client=self,
            max_wait=max_wait,
            timeout=timeout,
        )


TransactionManager = AsyncTransactionManager[Prisma]


# TODO: this should return the results as well
# TODO: don't require copy-pasting arguments between actions and batch actions
class Batch:
    ingestionlogs: 'IngestionLogsBatchActions'
    banktransactions: 'BankTransactionsBatchActions'
    internalpayments: 'InternalPaymentsBatchActions'
    internalreceivables: 'InternalReceivablesBatchActions'

    def __init__(self, client: Prisma) -> None:
        self.__client = client
        self.__queries: List[str] = []
        self._active_provider = client._active_provider
        self.ingestionlogs = IngestionLogsBatchActions(self)
        self.banktransactions = BankTransactionsBatchActions(self)
        self.internalpayments = InternalPaymentsBatchActions(self)
        self.internalreceivables = InternalReceivablesBatchActions(self)

    def _add(self, **kwargs: Any) -> None:
        builder = QueryBuilder(
            **kwargs,
            prisma_models=PRISMA_MODELS,
            relational_field_mappings=RELATIONAL_FIELD_MAPPINGS,
        )
        self.__queries.append(builder.build_query())

    async def commit(self) -> None:
        """Execute the queries"""
        # TODO: normalise this, we should still call client._execute
        queries = self.__queries
        self.__queries = []

        payload = {
            'batch': [
                {
                    'query': query,
                    'variables': {},
                }
                for query in queries
            ],
            'transaction': True,
        }
        await self.__client._engine.query(
            dumps(payload),
            tx_id=self.__client._tx_id,
        )

    def execute_raw(self, query: LiteralString, *args: Any) -> None:
        self._add(
            method='execute_raw',
            arguments={
                'query': query,
                'parameters': args,
            }
        )

    async def __aenter__(self) -> 'Batch':
        return self

    async def __aexit__(
        self,
        exc_type: Optional[Type[BaseException]],
        exc: Optional[BaseException],
        exc_tb: Optional[TracebackType],
    ) -> None:
        if exc is None:
            await self.commit()


# NOTE: some arguments are meaningless in this context but are included
# for completeness sake
class IngestionLogsBatchActions:
    def __init__(self, batcher: Batch) -> None:
        self._batcher = batcher

    def create(
        self,
        data: types.IngestionLogsCreateInput,
        include: Optional[types.IngestionLogsInclude] = None
    ) -> None:
        self._batcher._add(
            method='create',
            model=models.IngestionLogs,
            arguments={
                'data': data,
                'include': include,
            },
        )

    def create_many(
        self,
        data: List[types.IngestionLogsCreateWithoutRelationsInput],
        *,
        skip_duplicates: Optional[bool] = None,
    ) -> None:
        if skip_duplicates and self._batcher._active_provider in CREATE_MANY_SKIP_DUPLICATES_UNSUPPORTED:
            raise errors.UnsupportedDatabaseError(self._batcher._active_provider, 'create_many_skip_duplicates')

        self._batcher._add(
            method='create_many',
            model=models.IngestionLogs,
            arguments={
                'data': data,
                'skipDuplicates': skip_duplicates,
            },
            root_selection=['count'],
        )

    def delete(
        self,
        where: types.IngestionLogsWhereUniqueInput,
        include: Optional[types.IngestionLogsInclude] = None,
    ) -> None:
        self._batcher._add(
            method='delete',
            model=models.IngestionLogs,
            arguments={
                'where': where,
                'include': include,
            },
        )

    def update(
        self,
        data: types.IngestionLogsUpdateInput,
        where: types.IngestionLogsWhereUniqueInput,
        include: Optional[types.IngestionLogsInclude] = None
    ) -> None:
        self._batcher._add(
            method='update',
            model=models.IngestionLogs,
            arguments={
                'data': data,
                'where': where,
                'include': include,
            },
        )

    def upsert(
        self,
        where: types.IngestionLogsWhereUniqueInput,
        data: types.IngestionLogsUpsertInput,
        include: Optional[types.IngestionLogsInclude] = None,
    ) -> None:
        self._batcher._add(
            method='upsert',
            model=models.IngestionLogs,
            arguments={
                'where': where,
                'include': include,
                'create': data.get('create'),
                'update': data.get('update'),
            },
        )

    def update_many(
        self,
        data: types.IngestionLogsUpdateManyMutationInput,
        where: types.IngestionLogsWhereInput,
    ) -> None:
        self._batcher._add(
            method='update_many',
            model=models.IngestionLogs,
            arguments={'data': data, 'where': where,},
            root_selection=['count'],
        )

    def delete_many(
        self,
        where: Optional[types.IngestionLogsWhereInput] = None,
    ) -> None:
        self._batcher._add(
            method='delete_many',
            model=models.IngestionLogs,
            arguments={'where': where},
            root_selection=['count'],
        )



# NOTE: some arguments are meaningless in this context but are included
# for completeness sake
class BankTransactionsBatchActions:
    def __init__(self, batcher: Batch) -> None:
        self._batcher = batcher

    def create(
        self,
        data: types.BankTransactionsCreateInput,
        include: Optional[types.BankTransactionsInclude] = None
    ) -> None:
        self._batcher._add(
            method='create',
            model=models.BankTransactions,
            arguments={
                'data': data,
                'include': include,
            },
        )

    def create_many(
        self,
        data: List[types.BankTransactionsCreateWithoutRelationsInput],
        *,
        skip_duplicates: Optional[bool] = None,
    ) -> None:
        if skip_duplicates and self._batcher._active_provider in CREATE_MANY_SKIP_DUPLICATES_UNSUPPORTED:
            raise errors.UnsupportedDatabaseError(self._batcher._active_provider, 'create_many_skip_duplicates')

        self._batcher._add(
            method='create_many',
            model=models.BankTransactions,
            arguments={
                'data': data,
                'skipDuplicates': skip_duplicates,
            },
            root_selection=['count'],
        )

    def delete(
        self,
        where: types.BankTransactionsWhereUniqueInput,
        include: Optional[types.BankTransactionsInclude] = None,
    ) -> None:
        self._batcher._add(
            method='delete',
            model=models.BankTransactions,
            arguments={
                'where': where,
                'include': include,
            },
        )

    def update(
        self,
        data: types.BankTransactionsUpdateInput,
        where: types.BankTransactionsWhereUniqueInput,
        include: Optional[types.BankTransactionsInclude] = None
    ) -> None:
        self._batcher._add(
            method='update',
            model=models.BankTransactions,
            arguments={
                'data': data,
                'where': where,
                'include': include,
            },
        )

    def upsert(
        self,
        where: types.BankTransactionsWhereUniqueInput,
        data: types.BankTransactionsUpsertInput,
        include: Optional[types.BankTransactionsInclude] = None,
    ) -> None:
        self._batcher._add(
            method='upsert',
            model=models.BankTransactions,
            arguments={
                'where': where,
                'include': include,
                'create': data.get('create'),
                'update': data.get('update'),
            },
        )

    def update_many(
        self,
        data: types.BankTransactionsUpdateManyMutationInput,
        where: types.BankTransactionsWhereInput,
    ) -> None:
        self._batcher._add(
            method='update_many',
            model=models.BankTransactions,
            arguments={'data': data, 'where': where,},
            root_selection=['count'],
        )

    def delete_many(
        self,
        where: Optional[types.BankTransactionsWhereInput] = None,
    ) -> None:
        self._batcher._add(
            method='delete_many',
            model=models.BankTransactions,
            arguments={'where': where},
            root_selection=['count'],
        )



# NOTE: some arguments are meaningless in this context but are included
# for completeness sake
class InternalPaymentsBatchActions:
    def __init__(self, batcher: Batch) -> None:
        self._batcher = batcher

    def create(
        self,
        data: types.InternalPaymentsCreateInput,
        include: Optional[types.InternalPaymentsInclude] = None
    ) -> None:
        self._batcher._add(
            method='create',
            model=models.InternalPayments,
            arguments={
                'data': data,
                'include': include,
            },
        )

    def create_many(
        self,
        data: List[types.InternalPaymentsCreateWithoutRelationsInput],
        *,
        skip_duplicates: Optional[bool] = None,
    ) -> None:
        if skip_duplicates and self._batcher._active_provider in CREATE_MANY_SKIP_DUPLICATES_UNSUPPORTED:
            raise errors.UnsupportedDatabaseError(self._batcher._active_provider, 'create_many_skip_duplicates')

        self._batcher._add(
            method='create_many',
            model=models.InternalPayments,
            arguments={
                'data': data,
                'skipDuplicates': skip_duplicates,
            },
            root_selection=['count'],
        )

    def delete(
        self,
        where: types.InternalPaymentsWhereUniqueInput,
        include: Optional[types.InternalPaymentsInclude] = None,
    ) -> None:
        self._batcher._add(
            method='delete',
            model=models.InternalPayments,
            arguments={
                'where': where,
                'include': include,
            },
        )

    def update(
        self,
        data: types.InternalPaymentsUpdateInput,
        where: types.InternalPaymentsWhereUniqueInput,
        include: Optional[types.InternalPaymentsInclude] = None
    ) -> None:
        self._batcher._add(
            method='update',
            model=models.InternalPayments,
            arguments={
                'data': data,
                'where': where,
                'include': include,
            },
        )

    def upsert(
        self,
        where: types.InternalPaymentsWhereUniqueInput,
        data: types.InternalPaymentsUpsertInput,
        include: Optional[types.InternalPaymentsInclude] = None,
    ) -> None:
        self._batcher._add(
            method='upsert',
            model=models.InternalPayments,
            arguments={
                'where': where,
                'include': include,
                'create': data.get('create'),
                'update': data.get('update'),
            },
        )

    def update_many(
        self,
        data: types.InternalPaymentsUpdateManyMutationInput,
        where: types.InternalPaymentsWhereInput,
    ) -> None:
        self._batcher._add(
            method='update_many',
            model=models.InternalPayments,
            arguments={'data': data, 'where': where,},
            root_selection=['count'],
        )

    def delete_many(
        self,
        where: Optional[types.InternalPaymentsWhereInput] = None,
    ) -> None:
        self._batcher._add(
            method='delete_many',
            model=models.InternalPayments,
            arguments={'where': where},
            root_selection=['count'],
        )



# NOTE: some arguments are meaningless in this context but are included
# for completeness sake
class InternalReceivablesBatchActions:
    def __init__(self, batcher: Batch) -> None:
        self._batcher = batcher

    def create(
        self,
        data: types.InternalReceivablesCreateInput,
        include: Optional[types.InternalReceivablesInclude] = None
    ) -> None:
        self._batcher._add(
            method='create',
            model=models.InternalReceivables,
            arguments={
                'data': data,
                'include': include,
            },
        )

    def create_many(
        self,
        data: List[types.InternalReceivablesCreateWithoutRelationsInput],
        *,
        skip_duplicates: Optional[bool] = None,
    ) -> None:
        if skip_duplicates and self._batcher._active_provider in CREATE_MANY_SKIP_DUPLICATES_UNSUPPORTED:
            raise errors.UnsupportedDatabaseError(self._batcher._active_provider, 'create_many_skip_duplicates')

        self._batcher._add(
            method='create_many',
            model=models.InternalReceivables,
            arguments={
                'data': data,
                'skipDuplicates': skip_duplicates,
            },
            root_selection=['count'],
        )

    def delete(
        self,
        where: types.InternalReceivablesWhereUniqueInput,
        include: Optional[types.InternalReceivablesInclude] = None,
    ) -> None:
        self._batcher._add(
            method='delete',
            model=models.InternalReceivables,
            arguments={
                'where': where,
                'include': include,
            },
        )

    def update(
        self,
        data: types.InternalReceivablesUpdateInput,
        where: types.InternalReceivablesWhereUniqueInput,
        include: Optional[types.InternalReceivablesInclude] = None
    ) -> None:
        self._batcher._add(
            method='update',
            model=models.InternalReceivables,
            arguments={
                'data': data,
                'where': where,
                'include': include,
            },
        )

    def upsert(
        self,
        where: types.InternalReceivablesWhereUniqueInput,
        data: types.InternalReceivablesUpsertInput,
        include: Optional[types.InternalReceivablesInclude] = None,
    ) -> None:
        self._batcher._add(
            method='upsert',
            model=models.InternalReceivables,
            arguments={
                'where': where,
                'include': include,
                'create': data.get('create'),
                'update': data.get('update'),
            },
        )

    def update_many(
        self,
        data: types.InternalReceivablesUpdateManyMutationInput,
        where: types.InternalReceivablesWhereInput,
    ) -> None:
        self._batcher._add(
            method='update_many',
            model=models.InternalReceivables,
            arguments={'data': data, 'where': where,},
            root_selection=['count'],
        )

    def delete_many(
        self,
        where: Optional[types.InternalReceivablesWhereInput] = None,
    ) -> None:
        self._batcher._add(
            method='delete_many',
            model=models.InternalReceivables,
            arguments={'where': where},
            root_selection=['count'],
        )



Client = Prisma